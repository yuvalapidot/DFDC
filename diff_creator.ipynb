{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "import math\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.cm as cm\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "from PIL import Image\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "plt.rcParams[\"image.cmap\"] = 'hsv'\n",
    "plt.rcParams[\"animation.embed_limit\"] = 1866"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def video_read(video_path):\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    buf = np.empty((frame_count, frame_height, frame_width, 3), np.dtype('uint8'))\n",
    "    fc = 0\n",
    "    ret = True\n",
    "    while fc < frame_count and ret:\n",
    "        ret, frame = video.read()\n",
    "        if ret:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            buf[fc] = frame\n",
    "            fc += 1\n",
    "    video.release()\n",
    "    return fc, buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def video_write(buf, out_path):\n",
    "    out = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*'mp4v'), 30, (buf.shape[2], buf.shape[1]), isColor=False)\n",
    "    buf = buf.astype('uint8')\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    for frame in buf:\n",
    "        out.write(cv2.morphologyEx(frame, cv2.MORPH_CLOSE, kernel))\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def refine_faces(faces, probability_threshold=0.35):\n",
    "    faces = list(filter(lambda face: np.mean(face[\"probs\"]) / 100 > probability_threshold, faces))\n",
    "    def interp_array(arr):\n",
    "        l = len(arr)\n",
    "        fp = arr[arr > 0]\n",
    "        xp = (arr > 0) * (np.arange(l) + 1) \n",
    "        xp = xp[xp > 0] - 1\n",
    "        return np.interp(np.arange(l), xp, fp)\n",
    "    for face in faces:\n",
    "        face[\"centers_x\"] = interp_array(np.array(face[\"centers_x\"]))\n",
    "        face[\"centers_y\"] = interp_array(np.array(face[\"centers_y\"]))\n",
    "        face[\"widths\"] = interp_array(np.array(face[\"widths\"]))\n",
    "        face[\"heights\"] = interp_array(np.array(face[\"heights\"]))\n",
    "        face[\"probs\"] = np.array(face[\"probs\"])\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def crop_faces(video, faces_info, size=350):\n",
    "    video_height = video.shape[1]\n",
    "    video_width = video.shape[2]\n",
    "    def top(y):\n",
    "        return 0 if y < size / 2 else video_height - size if y + (size / 2) > video_height else int(y - (size / 2))\n",
    "    def bottom(y):\n",
    "        return size if y < size / 2 else video_height if y + (size / 2) > video_height else int(y + (size / 2))\n",
    "    def left(x):\n",
    "        return 0 if x < size / 2 else video_width - size if x + (size / 2) > video_width else int(x - (size / 2))\n",
    "    def right(x):\n",
    "        return size if x < size / 2 else video_width if x + (size / 2) > video_width else int(x + (size / 2))\n",
    "    faces_crops = [[(frame, top(y), bottom(y), left(x), right(x))\n",
    "             for frame, (x, y) in enumerate(zip(face[\"centers_x\"], face[\"centers_y\"]))]\n",
    "             for face in faces_info]\n",
    "    return np.stack(\n",
    "        [np.stack(\n",
    "            [video[frame, top:bottom, left:right, :] for frame, top, bottom, left, right in crops]\n",
    "        ) for crops in faces_crops])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def read_metadata(path):\n",
    "    metadata_file = open(path)\n",
    "    metadata = json.load(metadata_file)\n",
    "    metadata_file.close()\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dir = \"D:\\\\Projects\\\\DFDC\\\\Data\"\n",
    "metadata_file_name = 'metadata-processed.json'\n",
    "\n",
    "metadata = read_metadata(\"{}\\\\{}\".format(dir, metadata_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Video: xbvjrriwxn.mp4\n",
      "Fake Videos: ['akfrnoqubc.mp4']\n"
     ]
    }
   ],
   "source": [
    "video_name = 'akfrnoqubc.mp4'\n",
    "video_info = metadata[video_name]\n",
    "video_sub_dir = video_info['dir']\n",
    "if video_info['label'] == 'FAKE':\n",
    "    fake_names = [video_name]\n",
    "    real_name = video_info['original']\n",
    "elif video_info['label'] == 'REAL':\n",
    "    real_name = video_name\n",
    "    fake_names = video_info['fakes']\n",
    "else:\n",
    "    real_name = video_name\n",
    "    fake_names = []\n",
    "real_info = metadata[real_name]\n",
    "if 'faces' not in real_info:\n",
    "    print(\"Not enough metadata\")\n",
    "    raise TypeError(\"Not enough metadata\")\n",
    "print(\"Original Video: {}\".format(real_name))\n",
    "print(\"Fake Videos: {}\".format(fake_names))\n",
    "fake_order = 0\n",
    "fake_name = fake_names[fake_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frames: 300\n"
     ]
    }
   ],
   "source": [
    "real_fc, real_video = video_read(\"{}\\\\{}\\\\{}\".format(dir, video_sub_dir, real_name))\n",
    "fake_fc, fake_video = video_read(\"{}\\\\{}\\\\{}\".format(dir, video_sub_dir, fake_name))\n",
    "fc = min(real_fc, fake_fc)\n",
    "real_video = real_video[:fc]\n",
    "fake_video = fake_video[:fc]\n",
    "print(\"Number of frames: {0}\".format(fc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video has 2 suspected faces. Refining faces...\n",
      "2 faces were refined\n"
     ]
    }
   ],
   "source": [
    "faces_info = real_info['faces']\n",
    "print('Video has {} suspected faces. Refining faces...'.format(len(faces_info)))\n",
    "faces_info = refine_faces(faces_info)\n",
    "print('{} faces were refined'.format(len(faces_info)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "real_faces = crop_faces(real_video, faces_info)\n",
    "fake_faces = crop_faces(fake_video, faces_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "diff = np.sqrt(np.sum(np.square(np.subtract(real_faces, fake_faces)), axis=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diff min: 0.0\n",
      "Diff max: 27.331300737432898\n"
     ]
    }
   ],
   "source": [
    "diff_min = np.min(diff)\n",
    "print(\"Diff min: {0}\".format(diff_min))\n",
    "diff_max = np.max(diff)\n",
    "print(\"Diff max: {0}\".format(diff_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 18.384776310850235\n"
     ]
    }
   ],
   "source": [
    "top_percentage = 2\n",
    "threshold = np.percentile(diff, 100 - (top_percentage / diff.shape[0]))\n",
    "print(\"Threshold: {0}\".format(threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# plt.hist(diff.flatten(), bins=range(math.ceil(diff_max)))\n",
    "# plt.plot([threshold, threshold], [0, 1000000], linestyle='--', scalex=False)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# gray_diff = (diff - diff_min) * (255 / (diff_max - diff_min))\n",
    "# gray_threshold = (threshold - diff_min) * (255 / (diff_max - diff_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "mask = diff > threshold\n",
    "filtered_diff = diff * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# diff_ani = draw_videos([real_faces, filtered_diff, fake_faces], [cm.viridis, cm.gray, cm.viridis], [\"Original\", \"Diff\", \"Fake\"], fc)\n",
    "# diff_ani = draw_videos([real_faces, filtered_diff], [cm.viridis, cm.gray], [\"Original\", \"Diff\"], fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# diff_ani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.01043368 0.46122874]\n",
      "  [0.00961949 0.44303835]\n",
      "  [0.02462668 0.71047387]\n",
      "  ...\n",
      "  [0.17433562 1.88921292]\n",
      "  [0.18974124 1.9764817 ]\n",
      "  [0.19416869 2.00309876]]\n",
      "\n",
      " [[0.66943944 3.68430951]\n",
      "  [0.67035132 3.68691793]\n",
      "  [0.69042937 3.7427886 ]\n",
      "  ...\n",
      "  [0.12238578 1.59401729]\n",
      "  [0.0969571  1.42094943]\n",
      "  [0.09559702 1.40663877]]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 1 1 1 1 0 1 1 1 0\n",
      " 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 1 1 1 1 0 1 1 1 0\n",
      " 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1]\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "[109, 165, 178]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DBSCAN' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-2515b2d936d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrong_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdbscan\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdbscans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdbscan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwrong_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdbscan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwrong_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DBSCAN' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "# X = np.stack([np.mean(filtered_diff, axis=(2, 3))], axis=2)\n",
    "X = np.stack((np.mean(filtered_diff, axis=(2, 3)), np.std(filtered_diff, axis=(2,3))), axis=2)\n",
    "# X = np.reshape(filtered_diff, (filtered_diff.shape[0], filtered_diff.shape[1], filtered_diff.shape[2] * filtered_diff.shape[3]))\n",
    "print(X)\n",
    "# kmeans = [KMeans(n_clusters=2, random_state=0).fit(x) for x in X]\n",
    "# for kmean in kmeans:\n",
    "#     print(kmean.inertia_)\n",
    "#     print(kmean.labels_)\n",
    "#     print(kmean.cluster_centers_)\n",
    "#     print(kmean.score(kmean.cluster_centers_ - 1))\n",
    "# wrong = kmeans[0].labels_ - kmeans[1].labels_\n",
    "dbscans = [DBSCAN(eps=0.25, min_samples=1).fit(x) for x in X]\n",
    "for dbscan in dbscans:\n",
    "    print(dbscan.labels_)\n",
    "wrong = dbscans[0].labels_ - dbscans[1].labels_\n",
    "print(wrong)\n",
    "wrong_index = []\n",
    "for i, x in enumerate(wrong):\n",
    "    if x != 0:\n",
    "        wrong_index.append(i)\n",
    "print(wrong_index)\n",
    "for x, dbscan in zip(X, dbscans):\n",
    "    print(dbscan.predict([x[index] for index in wrong_index]))\n",
    "    print([dbscan.score([x[index]]) for index in wrong_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# def video_write(buf, out_path):\n",
    "#     out = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*'mp4v'), 30, (buf.shape[2], buf.shape[1]), isColor=False)\n",
    "#     buf = buf.astype('uint8')\n",
    "#     kernel = np.ones((2,2),np.uint8)\n",
    "#     for frame in buf:\n",
    "#         f = frame\n",
    "# #         f = cv2.morphologyEx(cv2.morphologyEx(f, cv2.MORPH_CLOSE, kernel), cv2.MORPH_OPEN, kernel)\n",
    "# #         f = cv2.morphologyEx(cv2.morphologyEx(f, cv2.MORPH_CLOSE, kernel), cv2.MORPH_OPEN, kernel)\n",
    "# #         f = cv2.morphologyEx(cv2.morphologyEx(f, cv2.MORPH_CLOSE, kernel), cv2.MORPH_OPEN, kernel)\n",
    "# #         f = cv2.morphologyEx(cv2.morphologyEx(f, cv2.MORPH_CLOSE, kernel), cv2.MORPH_OPEN, kernel)\n",
    "#         out.write(f)\n",
    "#     out.release()\n",
    "\n",
    "# for i, face_diff in enumerate(filtered_diff):\n",
    "#     out_path = \"{}\\\\{}\\\\{}_face_diff_{}.mp4\".format(dir, video_sub_dir, fake_name[:fake_name.find('.')], i)\n",
    "#     print(out_path)\n",
    "#     video_write(face_diff, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# def draw_videos(videos_cols, columns_color_maps, columns_titles, fc):\n",
    "#     cols = len(videos_cols)\n",
    "#     rows = max(map(lambda col: len(col), videos_cols))\n",
    "#     fig, ax = plt.subplots(nrows=rows, ncols=cols, squeeze=False, figsize=(10 * cols, 10 * rows))\n",
    "#     #TO CHECK\n",
    "#     im = [[ax[j, i].imshow(video[0], cmap=columns_color_maps[i], animated=True)\n",
    "#            for j, video in enumerate(col)] \n",
    "#           for i, col in enumerate(videos_cols)]      \n",
    "#     for i, title in enumerate(columns_titles): ax[0][i].title.set_text(title)\n",
    "#     def draw(frame_count):\n",
    "#         # TO CHECK\n",
    "#         [im[i][j].set_data(video[frame_count])\n",
    "#          for i, col in enumerate(videos_cols)\n",
    "#          for j, video in enumerate(col)]\n",
    "#     ani = animation.FuncAnimation(fig, draw, interval=30, save_count=fc)\n",
    "#     return ani"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DFDC",
   "language": "python",
   "name": "dfdc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
